{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84915dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d113d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and Settings\n",
    "\n",
    "# File path for the raw stocks daily data\n",
    "current_directory = os.getcwd()\n",
    "raw_data_file = os.path.join(current_directory, 'Data', 'raw_data.csv')\n",
    "\n",
    "# File path for the daily riskfree rate data\n",
    "riskfree_rate_data_file = os.path.join(current_directory, 'Data', 'riskfree_rate_data.csv')\n",
    "\n",
    "# Estimation (in sample) period dates\n",
    "in_sample_start_date = pd.to_datetime(\"2000-01-01\")\n",
    "in_sample_end_date = pd.to_datetime(\"2015-12-31\")\n",
    "\n",
    "# Out-of-sample period dates\n",
    "out_sample_start_date = pd.to_datetime(\"2016-01-01\")\n",
    "out_sample_end_date = pd.to_datetime(\"2024-12-31\")\n",
    "\n",
    "# File path to save information on top 50 stocks\n",
    "top50_stocks_info_path = os.path.join(current_directory, 'Data', 'top50_stocks_info.csv')\n",
    "\n",
    "# File path to save the cleaned and filtered data file\n",
    "clean_filtered_data_path = os.path.join(current_directory, 'Data', 'clean_filtered_data.csv')\n",
    "\n",
    "# Define necessary columns from raw stocks data\n",
    "neccessary_columns = [\"PERMNO\", \"SecurityNm\", \"Ticker\", \"SICCD\", \"Date\", \"DlyPrc\", \"DlyRet\", \"DlyVol\", \"ShrOut\"]\n",
    "\n",
    "# Define Energy industry SIC code ranges\n",
    "energy_sic_ranges = [(1300, 1399), (4900, 4999)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae87398",
   "metadata": {},
   "source": [
    "### Raw Data Information\n",
    "\n",
    "**Raw Stocks Data:**\n",
    "- Stock Daily Security Data from CRSP Stock - Version 2 (CIZ) \n",
    "- Columns: \"PERMNO\" (unique permanent identification numbers assigned by CRSP to all companies listed in CRSP dataset), \"SecurityNm\" (Security Name), \"Ticker\", \"SICCD\" (SIC Code), \"DateDlyCalDt\" (Date), \"DlyPrc\" (Daily Price), \"DlyRet\" (Daily Return), \"DlyVol\" (Daily Volume), \"ShrOut\" (Shares Outstanding)\n",
    "- SIC Code Range: 1300-1399 (Oil and Gas Extraction), 4900-4999 (Utilities - Energy)\n",
    "- Date Range: 2000-01-01 to 2024-12-31\n",
    "\n",
    "**Risk Free Rate Data:**\n",
    "- 4-week Riskfree Series from CRSP Treasuries \n",
    "- Columns: \"KYTREASNOX\", \"TIDXFAM\", \"TTERMTYPE\", \"TTERMLBL\", \"CALDT\", \"TDYLD\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98c4a6",
   "metadata": {},
   "source": [
    "### Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e96a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw stocks daily data and daily riskfree rate data files into a pandas DataFrames\n",
    "df_stocks = pd.read_csv(raw_data_file)\n",
    "df_rf = pd.read_csv(riskfree_rate_data_file)\n",
    "\n",
    "# Ensure the date columns are in datetime format\n",
    "df_stocks[\"DlyCalDt\"] = pd.to_datetime(df_stocks[\"DlyCalDt\"])\n",
    "df_stocks.rename(columns={\"DlyCalDt\": \"Date\"}, inplace=True)\n",
    "\n",
    "df_rf[\"CALDT\"] = pd.to_datetime(df_rf[\"CALDT\"])\n",
    "df_rf.rename(columns={\"CALDT\": \"Date\"}, inplace=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "df_stocks = df_stocks[neccessary_columns]\n",
    "\n",
    "print(df_stocks.head(5))\n",
    "print(df_rf.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cffaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing daily returns\n",
    "df_stocks.dropna(subset=\"DlyRet\", axis=0, inplace=True, ignore_index=True)\n",
    "\n",
    "# Calculate daily excess returns using dailyÂ risk free rate\n",
    "df = df_stocks.merge(df_rf[[\"Date\", \"TDYLD\"]], how=\"left\", on=\"Date\")\n",
    "df[\"TDYLD\"] = df[\"TDYLD\"].ffill()\n",
    "\n",
    "df[\"excess_return\"] = df[\"DlyRet\"] - df[\"TDYLD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9353134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique stocks\n",
    "num_stocks = df['PERMNO'].nunique()\n",
    "print(f\"Number of unique stocks: {num_stocks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987dea77",
   "metadata": {},
   "source": [
    "### Step 2: Clean and Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb92bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with duplicate data\n",
    "df.drop_duplicates(subset=['PERMNO', 'Date', \"excess_return\"], keep='first', inplace=True, ignore_index=True)\n",
    "\n",
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816cba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stocks with incomplete data (all stocks should be traded for all trading days)\n",
    "\n",
    "# Build the Common Trading Calendar\n",
    "common_trading_days = np.sort(df[\"Date\"].unique())\n",
    "\n",
    "expected_days = len(common_trading_days)\n",
    "print(f\"Number of trading days: {expected_days}\")\n",
    "\n",
    "# Group the data by stock (PERMNO) and count distinct trading days\n",
    "stock_counts = df.groupby(\"PERMNO\")[\"Date\"].nunique().reset_index()\n",
    "\n",
    "# Identify stocks that have complete data\n",
    "valid_stocks = stock_counts[stock_counts[\"Date\"] == expected_days][\"PERMNO\"].tolist()\n",
    "print(f\"Number of stocks with complete data for all trading days: {len(valid_stocks)}\")\n",
    "\n",
    "# Report stocks removed\n",
    "removed_stocks = stock_counts[stock_counts[\"Date\"] < expected_days][\"PERMNO\"].tolist()\n",
    "print(f\"Number of stocks removed due to incomplete data: {len(removed_stocks)}\")\n",
    "\n",
    "# Filter the main DataFrame to keep only the stocks with complete data\n",
    "df_clean = df[df[\"PERMNO\"].isin(valid_stocks)].copy()\n",
    "print(df_clean.head())\n",
    "print(df_clean.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 50 stocks by average market cap over the estimation period\n",
    "\n",
    "# Split data into in-sample and out-of-sample dataframes\n",
    "df_in_sample = df_clean[(df_clean[\"Date\"] >= in_sample_start_date) & (df_clean[\"Date\"] <= in_sample_end_date)].copy()\n",
    "\n",
    "# Compute average market cap per stock over the estimation period\n",
    "df_in_sample[\"market_cap\"] = df_in_sample[\"DlyPrc\"].abs() * df_in_sample[\"ShrOut\"]\n",
    "avg_market_cap = df_in_sample.groupby(\"PERMNO\")[\"market_cap\"].mean().reset_index().rename(columns={\"market_cap\": \"avg_market_cap\"})\n",
    "\n",
    "stock_info = df_in_sample.groupby(\"PERMNO\").agg({\"Ticker\": \"last\", \"SecurityNm\": \"last\"}).reset_index()   # Using \"last\" to get newest/latest ticker and company name if a company undergoes name change, etc.\n",
    "avg_market_cap = avg_market_cap.merge(stock_info, on=\"PERMNO\", how=\"left\")\n",
    "\n",
    "# Select the top 50 stocks\n",
    "top50_df = avg_market_cap.sort_values(by=\"avg_market_cap\", ascending=False).head(50)\n",
    "top50_permno = top50_df[\"PERMNO\"].tolist()\n",
    "\n",
    "print(\"Top 50 stocks:\")\n",
    "top50_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a04c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save information about top 50 stocks by average market cap\n",
    "top50_df.to_csv(top50_stocks_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bf40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to include only top 50 stocks by average market cap over the estimation period\n",
    "df_filtered = df_clean[df_clean[\"PERMNO\"].isin(top50_permno)].copy().reset_index()\n",
    "df_filtered.drop([\"SICCD\", \"DlyPrc\", \"DlyRet\", \"DlyVol\", \"ShrOut\", \"TDYLD\"], axis=1, inplace=True)\n",
    "print(\"Cleaned and filtered data:\")\n",
    "print(df_filtered.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad062a",
   "metadata": {},
   "source": [
    "### Step 3: Save Cleaned and Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20975ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean and filtered \n",
    "df_filtered = df_filtered.sort_values(['PERMNO', 'Date'])\n",
    "df_filtered.to_csv(clean_filtered_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705254bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
