{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from timesfm import TimesFm, TimesFmHparams, TimesFmCheckpoint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and Settings\n",
    "\n",
    "# Parameters for data split\n",
    "WINDOW = 21    # rolling window size to use as predictors\n",
    "DATE_COL = 'Date'\n",
    "ID_COL = 'PERMNO'\n",
    "TARGET_COL = 'excess_return'\n",
    "\n",
    "# File path for the cleaned and filtered data file\n",
    "current_directory = os.getcwd()\n",
    "clean_filtered_data_path = os.path.join(current_directory, 'Data', 'clean_filtered_data.csv')\n",
    "\n",
    "# File path to save prediction results\n",
    "results_path = os.path.join(current_directory, 'Results', f'timesfm_models_results{WINDOW:.0f}.csv')\n",
    "\n",
    "# Estimation (in sample) period dates\n",
    "in_sample_start_date = pd.to_datetime(\"2000-01-01\")\n",
    "in_sample_end_date = pd.to_datetime(\"2015-12-31\")\n",
    "\n",
    "# Out-of-sample period dates\n",
    "out_sample_start_date = pd.to_datetime(\"2016-01-01\")\n",
    "out_sample_end_date = pd.to_datetime(\"2024-12-31\")\n",
    "\n",
    "# Use GPU if available, else default to using CPU\n",
    "device_map = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9171280",
   "metadata": {},
   "source": [
    "### Step 1: Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ceb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned and filtered data files for in sample and out of sample periods into a pandas DataFrames\n",
    "df = pd.read_csv(clean_filtered_data_path)\n",
    "\n",
    "# Ensure the date columns are in datetime format\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "\n",
    "df = df[[ID_COL, DATE_COL, TARGET_COL]].dropna()\n",
    "df = df.sort_values([ID_COL, DATE_COL]).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique stocks\n",
    "stocks_permno = df[\"PERMNO\"].unique().tolist()\n",
    "print(f\"Number of unique stocks: {len(stocks_permno)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ded843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spit data into estimation (in-sample) and out-of-sample data\n",
    "df_train = df[(df[DATE_COL] >= in_sample_start_date) & (df[DATE_COL] <= in_sample_end_date)].copy().reset_index(drop=True)\n",
    "out_sample_start_date = df_train[DATE_COL].tail(WINDOW).iloc[0]\n",
    "df_test = df[(df[DATE_COL] >= out_sample_start_date) & (df[DATE_COL] <= out_sample_end_date)].copy().reset_index(drop=True)\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281024c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling window for predictors\n",
    "contexts = []\n",
    "targets = []\n",
    "records = []\n",
    "\n",
    "for id, grp in df_test.groupby(ID_COL):\n",
    "    values = grp[TARGET_COL].values\n",
    "    dates = grp[DATE_COL].values\n",
    "    for i in range(len(values) - WINDOW):\n",
    "        contexts.append(values[i:i+WINDOW])\n",
    "        targets.append(values[i+WINDOW])\n",
    "        records.append({\n",
    "            ID_COL: id,\n",
    "            TARGET_COL: values[i+WINDOW],\n",
    "            DATE_COL: dates[i+WINDOW]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.Series(targets)\n",
    "\n",
    "results = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8208de1e",
   "metadata": {},
   "source": [
    "### Step 2: Zero-Shot Forecasting with TimesFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Function to Calculate Predictive-R2 Used in the Finance Literature\n",
    "def r2(y_true, y_pred):\n",
    "    return 1-(((y_true-y_pred)**2).sum()/(y_true**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ac7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Shot TimesFM-1.0-200M\n",
    "tfm1 = TimesFm(\n",
    "    hparams = TimesFmHparams(\n",
    "        context_len = int(32 * np.ceil(WINDOW / 32)),   # context length should be multiple of 32\n",
    "        horizon_len = 1,\n",
    "        input_patch_len = 32,                           # fixed for 200m model\n",
    "        output_patch_len = 128,                         # fixed for 200m model\n",
    "        num_layers = 20,                                # fixed for 200m model\n",
    "        model_dims = 1280,                              # fixed for 200m model\n",
    "        backend = device_map       \n",
    "        ),\n",
    "    checkpoint = TimesFmCheckpoint(huggingface_repo_id=\"google/timesfm-1.0-200m-pytorch\")\n",
    "    )\n",
    "\n",
    "freqs = [0] * len(contexts)\n",
    "preds, _ = tfm1.forecast(contexts, freq=freqs)\n",
    "\n",
    "y_tfm1 = pd.Series(preds.reshape([-1,]))\n",
    "\n",
    "results['y_tfm1'] = y_tfm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dba8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Shot TimesFM-2.0-500M\n",
    "tfm2 = TimesFm(\n",
    "    hparams = TimesFmHparams(\n",
    "        context_len = int(32 * np.ceil(WINDOW / 32)),   # context length should be multiple of 32\n",
    "        horizon_len = 1,\n",
    "        input_patch_len = 32,                           # fixed for 500m model\n",
    "        output_patch_len = 128,                         # fixed for 500m model\n",
    "        num_layers = 50,                                # fixed for 500m model\n",
    "        model_dims = 1280,                              # fixed for 500m model\n",
    "        backend = device_map       \n",
    "        ),\n",
    "    checkpoint = TimesFmCheckpoint(huggingface_repo_id=\"google/timesfm-2.0-500m-pytorch\")\n",
    "    )\n",
    "\n",
    "freqs = [0] * len(contexts)\n",
    "preds, _ = tfm2.forecast(contexts, freq=freqs)\n",
    "\n",
    "y_tfm2 = pd.Series(preds.reshape([-1,]))\n",
    "\n",
    "results['y_tfm2'] = y_tfm2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3ee4a",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate Statistical Performance of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "\n",
    "# TimesFM 1.0\n",
    "r2_tfm1  = r2(y_test, y_tfm1)\n",
    "mse_tfm1 = mean_squared_error(y_test, y_tfm1)\n",
    "mae_tfm1 = mean_absolute_error(y_test, y_tfm1)\n",
    "da_tfm1 = (np.sign(y_test) == np.sign(y_tfm1)).mean()\n",
    "\n",
    "# TimesFM 2.0\n",
    "r2_tfm2  = r2(y_test, y_tfm2)\n",
    "mse_tfm2 = mean_squared_error(y_test, y_tfm2)\n",
    "mae_tfm2 = mean_absolute_error(y_test, y_tfm2)\n",
    "da_tfm2 = (np.sign(y_test) == np.sign(y_tfm2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collating Results\n",
    "\n",
    "results_matrix = [{\n",
    "        \"Model\": \"TimesFM-1.0-200M\",\n",
    "        \"R-squared\": r2_tfm1,\n",
    "        \"MSE\": mse_tfm1,\n",
    "        \"MAE\": mae_tfm1,\n",
    "        \"Direction Accuracy\": da_tfm1\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"TimesFM-2.0-500M\",\n",
    "        \"R-squared\": r2_tfm2,\n",
    "        \"MSE\": mse_tfm2,\n",
    "        \"MAE\": mae_tfm2,\n",
    "        \"Direction Accuracy\": da_tfm2\n",
    "    }]\n",
    "\n",
    "results_matrix_df = pd.DataFrame(results_matrix)\n",
    "results_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5c2fa",
   "metadata": {},
   "source": [
    "##### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61553e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Prediction Results\n",
    "results.to_csv(results_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d96d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
