{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import torch\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and Settings\n",
    "\n",
    "# Parameters for data split\n",
    "WINDOW = 21    # rolling window size to use as predictors\n",
    "DATE_COL = 'Date'\n",
    "ID_COL = 'PERMNO'\n",
    "TARGET_COL = 'excess_return'\n",
    "\n",
    "# File path for the cleaned and filtered data file\n",
    "current_directory = os.getcwd()\n",
    "clean_filtered_data_path = os.path.join(current_directory, 'Data', 'clean_filtered_data.csv')\n",
    "\n",
    "# File path to save prediction results\n",
    "results_path = os.path.join(current_directory, 'Results', f'models_results{WINDOW:.0f}.csv')\n",
    "\n",
    "# File path to save best model parameters\n",
    "best_parameters_path = os.path.join(current_directory, 'Results', f'models_best_parameters{WINDOW:.0f}.csv')\n",
    "\n",
    "# Estimation (in sample) period dates\n",
    "in_sample_start_date = pd.to_datetime(\"2000-01-01\")\n",
    "in_sample_end_date = pd.to_datetime(\"2015-12-31\")\n",
    "\n",
    "# Out-of-sample period dates\n",
    "out_sample_start_date = pd.to_datetime(\"2016-01-01\")\n",
    "out_sample_end_date = pd.to_datetime(\"2024-12-31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874a2f5",
   "metadata": {},
   "source": [
    "### Step 1: Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned and filtered data files for in sample and out of sample periods into a pandas DataFrames (output from ETL step)\n",
    "df = pd.read_csv(clean_filtered_data_path)\n",
    "\n",
    "# Ensure the date columns are in datetime format\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "\n",
    "df = df[[ID_COL, DATE_COL, TARGET_COL]].dropna()\n",
    "df = df.sort_values([ID_COL, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ea5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique stocks\n",
    "stocks_permno = df[\"PERMNO\"].unique().tolist()\n",
    "print(f\"Number of unique stocks: {len(stocks_permno)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75669f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling window for predictors\n",
    "for lag in range(1, WINDOW+1):\n",
    "    df[f'lag_{lag}'] = df.groupby(ID_COL)[TARGET_COL].shift(lag)\n",
    "df = df.dropna(subset=[f'lag_{lag}' for lag in range(1, WINDOW+1)]).reset_index(drop=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4514d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spit data into estimation (in-sample) and out-of-sample data\n",
    "df_train = df[(df[DATE_COL] >= in_sample_start_date) & (df[DATE_COL] <= in_sample_end_date)].copy().reset_index(drop=True)\n",
    "df_test = df[(df[DATE_COL] >= out_sample_start_date) & (df[DATE_COL] <= out_sample_end_date)].copy().reset_index(drop=True)\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[[f'lag_{lag}' for lag in range(1, WINDOW+1)]].values\n",
    "y_train = df_train[TARGET_COL].values\n",
    "\n",
    "X_test = df_test[[f'lag_{lag}' for lag in range(1, WINDOW+1)]].values\n",
    "y_test = df_test[TARGET_COL].values\n",
    "\n",
    "results = df_test[[ID_COL, DATE_COL, TARGET_COL]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee85c76",
   "metadata": {},
   "source": [
    "### Step 2: Training Models and Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Function to Calculate Predictive-R2 Used in the Finance Literature\n",
    "def r2(y_true, y_pred):\n",
    "    return 1-(((y_true-y_pred)**2).sum()/(y_true**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Models\n",
    "\n",
    "# Ordinary Least Square\n",
    "ols = LinearRegression(n_jobs=-1)\n",
    "ols.fit(X_train, y_train)\n",
    "y_ols = ols.predict(X_test)\n",
    "\n",
    "# Penalized Linear Regression\n",
    "r2_lasso_best = -1000\n",
    "r2_ridge_best = -1000\n",
    "r2_enet_best = -1000\n",
    "\n",
    "for alpha in np.logspace(-10,-5,11):\n",
    "    # Lasso\n",
    "    lasso = Lasso(alpha=alpha, max_iter=2000, random_state=73, selection='random')\n",
    "    lasso.fit(X_train, y_train)\n",
    "    pred_lasso = lasso.predict(X_test)\n",
    "    r2_lasso_temp = r2(y_test, pred_lasso)\n",
    "    if r2_lasso_temp > r2_lasso_best:\n",
    "        y_lasso = pred_lasso\n",
    "        alpha_lasso = alpha\n",
    "        r2_lasso_best = r2_lasso_temp\n",
    "\n",
    "    # Elastic Net\n",
    "    for l1_r in [0.25,0.5,0.75]:\n",
    "        enet = ElasticNet(alpha=alpha, l1_ratio=l1_r, max_iter=2000, random_state=73, selection='random')\n",
    "        enet.fit(X_train, y_train)\n",
    "        pred_enet = enet.predict(X_test)\n",
    "        r2_enet_temp = r2(y_test, pred_enet)\n",
    "        if r2_enet_temp > r2_enet_best:\n",
    "            y_enet = pred_enet\n",
    "            alpha_enet = alpha\n",
    "            l1_r_enet = l1_r\n",
    "            r2_enet_best = r2_enet_temp\n",
    "\n",
    "for alpha in np.logspace(-5,0,11):\n",
    "    # Ridge\n",
    "    ridge = Ridge(alpha=alpha, max_iter=2000, random_state=73)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    pred_ridge = ridge.predict(X_test)\n",
    "    r2_ridge_temp = r2(y_test, pred_ridge)\n",
    "    if r2_ridge_temp > r2_ridge_best:\n",
    "        y_ridge = pred_ridge\n",
    "        alpha_ridge = alpha\n",
    "        r2_ridge_best = r2_ridge_temp\n",
    "\n",
    "\n",
    "results[\"y_ols\"] = y_ols\n",
    "results[\"y_lasso\"] = y_lasso\n",
    "results[\"y_enet\"] = y_enet\n",
    "results[\"y_ridge\"] = y_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78909360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Linear Models\n",
    "\n",
    "# Random Forest Regression\n",
    "r2_rf_best = -1000\n",
    "\n",
    "for leaf_size in [2, 5, 10, 20, 50]:\n",
    "    rf = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_leaf=leaf_size, n_jobs=-1, random_state=73)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_rf = rf.predict(X_test)\n",
    "    r2_rf_temp = r2(y_test, pred_rf)\n",
    "    if r2_rf_temp > r2_rf_best:\n",
    "        y_rf = pred_rf\n",
    "        leaf_size_rf = leaf_size\n",
    "        r2_rf_best = r2_rf_temp\n",
    "\n",
    "# XGBoost Regression\n",
    "r2_xgb_best = -1000\n",
    "\n",
    "for lr in [0.01, 0.1]:\n",
    "    xgb = XGBRegressor(n_estimators=1000, max_depth=2, learning_rate=lr, random_state=73, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    xgb.fit(X_train, y_train)\n",
    "    pred_xgb = xgb.predict(X_test)\n",
    "    r2_xgb_temp = r2(y_test, pred_xgb)\n",
    "    if r2_xgb_temp > r2_xgb_best:\n",
    "        y_xgb = pred_xgb\n",
    "        lr_xgb = lr\n",
    "        r2_xgb_best = r2_xgb_temp\n",
    "\n",
    "\n",
    "results[\"y_rf\"] = y_rf\n",
    "results[\"y_xgb\"] = y_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9242cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks\n",
    "\n",
    "# Model 1 (1 Layer)\n",
    "r2_nn1_best = -1000\n",
    "\n",
    "for alpha in [0.00001, 0.0001, 0.001]:\n",
    "    for lr in [0.001, 0.01]:\n",
    "        nn1 = MLPRegressor(hidden_layer_sizes=(64,), alpha=alpha, batch_size=500, learning_rate_init=lr, max_iter=100, random_state=73, early_stopping=True)\n",
    "        nn1.fit(X_train, y_train)\n",
    "        pred_nn1 = nn1.predict(X_test)\n",
    "        r2_nn1_temp = r2(y_test, pred_nn1)\n",
    "        if r2_nn1_temp > r2_nn1_best:\n",
    "            y_nn1 = pred_nn1\n",
    "            alpha_nn1 = alpha\n",
    "            lr_nn1 = lr\n",
    "            r2_nn1_best = r2_nn1_temp\n",
    "\n",
    "# Model 2 (2 Layers)\n",
    "r2_nn2_best = -1000\n",
    "\n",
    "for alpha in [0.00001, 0.0001, 0.001]:\n",
    "    for lr in [0.001, 0.01]:\n",
    "        nn2 = MLPRegressor(hidden_layer_sizes=(64,32,), alpha=alpha, batch_size=500, learning_rate_init=lr, max_iter=100, random_state=73, early_stopping=True)\n",
    "        nn2.fit(X_train, y_train)\n",
    "        pred_nn2 = nn2.predict(X_test)\n",
    "        r2_nn2_temp = r2(y_test, pred_nn2)\n",
    "        if r2_nn2_temp > r2_nn2_best:\n",
    "            y_nn2 = pred_nn2\n",
    "            alpha_nn2 = alpha\n",
    "            lr_nn2 = lr\n",
    "            r2_nn2_best = r2_nn2_temp\n",
    "\n",
    "# Model 3 (3 Layers)\n",
    "r2_nn3_best = -1000\n",
    "\n",
    "for alpha in [0.00001, 0.0001, 0.001]:\n",
    "    for lr in [0.001, 0.01]:\n",
    "        nn3 = MLPRegressor(hidden_layer_sizes=(64,32,16,), alpha=alpha, batch_size=500, learning_rate_init=lr, max_iter=100, random_state=73, early_stopping=True)\n",
    "        nn3.fit(X_train, y_train)\n",
    "        pred_nn3 = nn3.predict(X_test)\n",
    "        r2_nn3_temp = r2(y_test, pred_nn3)\n",
    "        if r2_nn3_temp > r2_nn3_best:\n",
    "            y_nn3 = pred_nn3\n",
    "            alpha_nn3 = alpha\n",
    "            lr_nn3 = lr\n",
    "            r2_nn3_best = r2_nn3_temp\n",
    "\n",
    "# Model 4 (4 Layers)\n",
    "r2_nn4_best = -1000\n",
    "\n",
    "for alpha in [0.00001, 0.0001, 0.001]:\n",
    "    for lr in [0.001, 0.01]:\n",
    "        nn4 = MLPRegressor(hidden_layer_sizes=(64,32,16,8,), alpha=alpha, batch_size=500, learning_rate_init=lr, max_iter=100, random_state=73, early_stopping=True)\n",
    "        nn4.fit(X_train, y_train)\n",
    "        pred_nn4 = nn4.predict(X_test)\n",
    "        r2_nn4_temp = r2(y_test, pred_nn4)\n",
    "        if r2_nn4_temp > r2_nn4_best:\n",
    "            y_nn4 = pred_nn4\n",
    "            alpha_nn4 = alpha\n",
    "            lr_nn4 = lr\n",
    "            r2_nn4_best = r2_nn4_temp\n",
    "\n",
    "# Model 5 (5 Layers)\n",
    "r2_nn5_best = -1000\n",
    "\n",
    "for alpha in [0.00001, 0.0001, 0.001]:\n",
    "    for lr in [0.001, 0.01]:\n",
    "        nn5 = MLPRegressor(hidden_layer_sizes=(64,32,16,8,4,), alpha=alpha, batch_size=500, learning_rate_init=lr, max_iter=100, random_state=73, early_stopping=True)\n",
    "        nn5.fit(X_train, y_train)\n",
    "        pred_nn5 = nn5.predict(X_test)\n",
    "        r2_nn5_temp = r2(y_test, pred_nn5)\n",
    "        if r2_nn5_temp > r2_nn5_best:\n",
    "            y_nn5 = pred_nn5\n",
    "            alpha_nn5 = alpha\n",
    "            lr_nn5 = lr\n",
    "            r2_nn5_best = r2_nn5_temp\n",
    "\n",
    "\n",
    "results[\"y_nn1\"] = y_nn1\n",
    "results[\"y_nn2\"] = y_nn2\n",
    "results[\"y_nn3\"] = y_nn3\n",
    "results[\"y_nn4\"] = y_nn4\n",
    "results[\"y_nn5\"] = y_nn5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317221fb",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate Statistical Performance of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "\n",
    "# Linear Models\n",
    "r2_ols = r2(y_test, y_ols)\n",
    "mse_ols = mean_squared_error(y_test, y_ols)\n",
    "mae_ols = mean_absolute_error(y_test, y_ols)\n",
    "da_ols = (np.sign(y_test) == np.sign(y_ols)).mean()\n",
    "\n",
    "r2_lasso = r2_lasso_best\n",
    "mse_lasso = mean_squared_error(y_test, y_lasso)\n",
    "mae_lasso = mean_absolute_error(y_test, y_lasso)\n",
    "da_lasso = (np.sign(y_test) == np.sign(y_lasso)).mean()\n",
    "\n",
    "r2_enet = r2_enet_best\n",
    "mse_enet = mean_squared_error(y_test, y_enet)\n",
    "mae_enet = mean_absolute_error(y_test, y_enet)\n",
    "da_enet = (np.sign(y_test) == np.sign(y_enet)).mean()\n",
    "\n",
    "r2_ridge = r2_ridge_best\n",
    "mse_ridge = mean_squared_error(y_test, y_ridge)\n",
    "mae_ridge = mean_absolute_error(y_test, y_ridge)\n",
    "da_ridge = (np.sign(y_test) == np.sign(y_ridge)).mean()\n",
    "\n",
    "# Non-Linear Models\n",
    "r2_rf = r2_rf_best\n",
    "mse_rf = mean_squared_error(y_test, y_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_rf)\n",
    "da_rf = (np.sign(y_test) == np.sign(y_rf)).mean()\n",
    "\n",
    "r2_xgb = r2_xgb_best\n",
    "mse_xgb = mean_squared_error(y_test, y_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_xgb)\n",
    "da_xgb = (np.sign(y_test) == np.sign(y_xgb)).mean()\n",
    "\n",
    "# Neural Networks\n",
    "r2_nn1 = r2_nn1_best\n",
    "mse_nn1 = mean_squared_error(y_test, y_nn1)\n",
    "mae_nn1 = mean_absolute_error(y_test, y_nn1)\n",
    "da_nn1 = (np.sign(y_test) == np.sign(y_nn1)).mean()\n",
    "\n",
    "r2_nn2 = r2_nn2_best\n",
    "mse_nn2 = mean_squared_error(y_test, y_nn2)\n",
    "mae_nn2 = mean_absolute_error(y_test, y_nn2)\n",
    "da_nn2 = (np.sign(y_test) == np.sign(y_nn2)).mean()\n",
    "\n",
    "r2_nn3 = r2_nn3_best\n",
    "mse_nn3 = mean_squared_error(y_test, y_nn3)\n",
    "mae_nn3 = mean_absolute_error(y_test, y_nn3)\n",
    "da_nn3 = (np.sign(y_test) == np.sign(y_nn3)).mean()\n",
    "\n",
    "r2_nn4 = r2_nn4_best\n",
    "mse_nn4 = mean_squared_error(y_test, y_nn4)\n",
    "mae_nn4 = mean_absolute_error(y_test, y_nn4)\n",
    "da_nn4 = (np.sign(y_test) == np.sign(y_nn4)).mean()\n",
    "\n",
    "r2_nn5 = r2_nn5_best\n",
    "mse_nn5 = mean_squared_error(y_test, y_nn5)\n",
    "mae_nn5 = mean_absolute_error(y_test, y_nn5)\n",
    "da_nn5 = (np.sign(y_test) == np.sign(y_nn5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d57f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate Results\n",
    "\n",
    "results_matrix = [\n",
    "    {\n",
    "        \"Model\": \"OLS\",\n",
    "        \"R-squared\": r2_ols,\n",
    "        \"MSE\": mse_ols,\n",
    "        \"MAE\": mae_ols,\n",
    "        \"Direction Accuracy\": da_ols\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Lasso\",\n",
    "        \"R-squared\": r2_lasso,\n",
    "        \"MSE\": mse_lasso,\n",
    "        \"MAE\": mae_lasso,\n",
    "        \"Direction Accuracy\": da_lasso\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Ridge\",\n",
    "        \"R-squared\": r2_ridge,\n",
    "        \"MSE\": mse_ridge,\n",
    "        \"MAE\": mae_ridge,\n",
    "        \"Direction Accuracy\": da_ridge\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Elastic Net\",\n",
    "        \"R-squared\": r2_enet,\n",
    "        \"MSE\": mse_enet,\n",
    "        \"MAE\": mae_enet,\n",
    "        \"Direction Accuracy\": da_enet\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Random Forest\",\n",
    "        \"R-squared\": r2_rf,\n",
    "        \"MSE\": mse_rf,\n",
    "        \"MAE\": mae_rf,\n",
    "        \"Direction Accuracy\": da_rf\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"XGBoost\",\n",
    "        \"R-squared\": r2_xgb,\n",
    "        \"MSE\": mse_xgb,\n",
    "        \"MAE\": mae_xgb,\n",
    "        \"Direction Accuracy\": da_xgb\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 1\",\n",
    "        \"R-squared\": r2_nn1,\n",
    "        \"MSE\": mse_nn1,\n",
    "        \"MAE\": mae_nn1,\n",
    "        \"Direction Accuracy\": da_nn1\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 2\",\n",
    "        \"R-squared\": r2_nn2,\n",
    "        \"MSE\": mse_nn2,\n",
    "        \"MAE\": mae_nn2,\n",
    "        \"Direction Accuracy\": da_nn2\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 3\",\n",
    "        \"R-squared\": r2_nn3,\n",
    "        \"MSE\": mse_nn3,\n",
    "        \"MAE\": mae_nn3,\n",
    "        \"Direction Accuracy\": da_nn3\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 4\",\n",
    "        \"R-squared\": r2_nn4,\n",
    "        \"MSE\": mse_nn4,\n",
    "        \"MAE\": mae_nn4,\n",
    "        \"Direction Accuracy\": da_nn4\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 5\",\n",
    "        \"R-squared\": r2_nn5,\n",
    "        \"MSE\": mse_nn5,\n",
    "        \"MAE\": mae_nn5,\n",
    "        \"Direction Accuracy\": da_nn5\n",
    "    }\n",
    "]\n",
    "\n",
    "results_matrix_df = pd.DataFrame(results_matrix)\n",
    "results_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28262de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Paramters\n",
    "\n",
    "best_parameters_matrix = [\n",
    "    {\n",
    "        \"Model\": \"OLS\",\n",
    "        \"Hidden Layers\": \"-\",\n",
    "        \"Parameters\": \"-\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Lasso\",\n",
    "        \"Hidden Layers\": \"-\",\n",
    "        \"Parameters\": f\"Alpha = {alpha_lasso}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Ridge\",\n",
    "        \"Hidden Layers\": \"-\",\n",
    "        \"Parameters\": f\"Alpha = {alpha_ridge}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Elastic Net\",\n",
    "        \"Hidden Layers\": \"-\",\n",
    "        \"Parameters\": f\"Alpha = {alpha_enet}; L1 Ratio = {l1_r_enet}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Random Forest\",\n",
    "        \"Hidden Layers\": \"-\",\n",
    "        \"Parameters\": f\"Minimum Sample per Leaf = {leaf_size_rf}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"XGBoost\",\n",
    "        \"Hidden Layers\": \"-\",\n",
    "        \"Parameters\": f\"Learning Rate = {lr_xgb}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 1\",\n",
    "        \"Hidden Layers\": \"32\",\n",
    "        \"Parameters\": f\"Alpha = {alpha_nn1}; Learning Rate = {lr_nn1}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 2\",\n",
    "        \"Hidden Layers\": \"32, 16\",\n",
    "        \"Parameters\": f\"Alpha = {alpha_nn2}; Learning Rate = {lr_nn2}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 3\",\n",
    "        \"Hidden Layers\": \"32, 16, 8\",\n",
    "        \"Parameters\": f\"Alpha = {alpha_nn3}; Learning Rate = {lr_nn3}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 4\",\n",
    "        \"Hidden Layers\": \"32, 16, 8, 4\",\n",
    "        \"Parameters\": f\"Alpha = {alpha_nn4}; Learning Rate = {lr_nn4}\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"NN 5\",\n",
    "        \"Hidden Layers\": \"32, 16, 8, 4, 2\",\n",
    "        \"Parameters\": f\"Alpha = {alpha_nn5}; Learning Rate = {lr_nn5}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "best_parameters_matrix_df = pd.DataFrame(best_parameters_matrix)\n",
    "best_parameters_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961155cd",
   "metadata": {},
   "source": [
    "##### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2283bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Prediction Results and Best Model Parameters\n",
    "results.to_csv(results_path, index=False)\n",
    "best_parameters_matrix_df.to_csv(best_parameters_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d015ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
